{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0S8H/1AjWfrSLTkiV6fuJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheAmirHK/Experiments/blob/main/FederatedLearning/FederatedLearning_with_FedAvg(test).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leT_0pdDcq5C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist_data():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "    train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "    num_clients = 5\n",
        "    data_size = len(train_dataset) // num_clients\n",
        "    client_data_indices = [list(range(i * data_size, (i + 1) * data_size)) for i in range(num_clients)]\n",
        "\n",
        "    client_datasets = [Subset(train_dataset, indices) for indices in client_data_indices]\n",
        "\n",
        "    return client_datasets\n",
        "\n",
        "client_datasets = load_mnist_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "F8fIep96dD7B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fed_avg(client_weights):\n",
        "\n",
        "    global_weights = client_weights[0].copy()\n",
        "    for key in global_weights.keys():\n",
        "        global_weights[key] = torch.stack([client_weights[i][key] for i in range(len(client_weights))], dim=0).mean(dim=0)\n",
        "    return global_weights"
      ],
      "metadata": {
        "id": "46LkEt9AdPYx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_local_model(client_id, model, dataset, epochs=1, lr=0.1):\n",
        "\n",
        "    model.train()\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for images, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "cBPgb5HhdQmh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_learning(num_rounds=20, num_clients=5):\n",
        "    global_model = SimpleNN()\n",
        "    client_models = [SimpleNN() for _ in range(num_clients)]\n",
        "\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"Round {round_num + 1}\")\n",
        "        client_weights = []\n",
        "\n",
        "        for client_id in range(num_clients):\n",
        "            client_model = client_models[client_id]\n",
        "            client_model.load_state_dict(global_model.state_dict())\n",
        "            client_dataset = client_datasets[client_id]\n",
        "            trained_weights = train_local_model(client_id, client_model, client_dataset, epochs=1)\n",
        "            client_weights.append(trained_weights)\n",
        "\n",
        "        global_weights = fed_avg(client_weights)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        test_accuracy = evaluate_global_model(global_model)\n",
        "        print(f\"Test Accuracy after Round {round_num + 1}: {test_accuracy:.2f}%\")\n",
        "\n",
        "def evaluate_global_model(model):\n",
        "    model.eval()\n",
        "    test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "federated_learning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVL6O0mGdRt5",
        "outputId": "e1690883-fa30-4ce5-9746-bc56b69832af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n",
            "Test Accuracy after Round 1: 82.85%\n",
            "Round 2\n",
            "Test Accuracy after Round 2: 85.85%\n",
            "Round 3\n",
            "Test Accuracy after Round 3: 90.48%\n",
            "Round 4\n",
            "Test Accuracy after Round 4: 92.32%\n",
            "Round 5\n",
            "Test Accuracy after Round 5: 92.59%\n",
            "Round 6\n",
            "Test Accuracy after Round 6: 93.78%\n",
            "Round 7\n",
            "Test Accuracy after Round 7: 93.58%\n",
            "Round 8\n",
            "Test Accuracy after Round 8: 94.33%\n",
            "Round 9\n",
            "Test Accuracy after Round 9: 94.47%\n",
            "Round 10\n",
            "Test Accuracy after Round 10: 94.49%\n",
            "Round 11\n",
            "Test Accuracy after Round 11: 95.14%\n",
            "Round 12\n",
            "Test Accuracy after Round 12: 94.86%\n",
            "Round 13\n",
            "Test Accuracy after Round 13: 94.68%\n",
            "Round 14\n",
            "Test Accuracy after Round 14: 94.84%\n",
            "Round 15\n",
            "Test Accuracy after Round 15: 95.14%\n",
            "Round 16\n",
            "Test Accuracy after Round 16: 95.50%\n",
            "Round 17\n",
            "Test Accuracy after Round 17: 95.01%\n",
            "Round 18\n",
            "Test Accuracy after Round 18: 95.43%\n",
            "Round 19\n",
            "Test Accuracy after Round 19: 95.61%\n",
            "Round 20\n",
            "Test Accuracy after Round 20: 95.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, I added a proximal term to the local training loss to penalize deviations from the global model weights. Well seems to be funny and accurate in long runs but won't be time-effeicient !\n",
        "\n",
        "def train_local_model_fedprox(client_id, model, global_weights, dataset, epochs=1, lr=0.1, mu=0.01):\n",
        "\n",
        "    model.train()\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for images, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            prox_term = 0.0\n",
        "            for param, global_param in zip(model.parameters(), global_weights.values()):\n",
        "                prox_term += torch.norm(param - global_param) ** 2\n",
        "\n",
        "            loss += (mu / 2) * prox_term\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict()"
      ],
      "metadata": {
        "id": "1rRF0ts3gAmb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_learning_fedprox(num_rounds=20, num_clients=5, mu=0.01):\n",
        "    global_model = SimpleNN()\n",
        "    client_models = [SimpleNN() for _ in range(num_clients)]\n",
        "\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"Round {round_num + 1}\")\n",
        "        client_weights = []\n",
        "\n",
        "        for client_id in range(num_clients):\n",
        "            client_model = client_models[client_id]\n",
        "            client_model.load_state_dict(global_model.state_dict())\n",
        "            client_dataset = client_datasets[client_id]\n",
        "\n",
        "            trained_weights = train_local_model_fedprox(\n",
        "                client_id, client_model, global_model.state_dict(), client_dataset, epochs=1, mu=mu\n",
        "            )\n",
        "            client_weights.append(trained_weights)\n",
        "\n",
        "        global_weights = fed_avg(client_weights)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        test_accuracy = evaluate_global_model(global_model)\n",
        "        print(f\"Test Accuracy after Round {round_num + 1}: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "yEJJ1SkxgGrC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "federated_learning_fedprox()"
      ],
      "metadata": {
        "id": "nWoXIEC8gNmj",
        "outputId": "790c84b9-3916-4056-ff6c-8d1c99b2151d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1\n",
            "Test Accuracy after Round 1: 72.90%\n",
            "Round 2\n",
            "Test Accuracy after Round 2: 83.00%\n",
            "Round 3\n",
            "Test Accuracy after Round 3: 88.88%\n",
            "Round 4\n",
            "Test Accuracy after Round 4: 90.66%\n",
            "Round 5\n",
            "Test Accuracy after Round 5: 91.87%\n",
            "Round 6\n",
            "Test Accuracy after Round 6: 93.39%\n",
            "Round 7\n",
            "Test Accuracy after Round 7: 93.89%\n",
            "Round 8\n",
            "Test Accuracy after Round 8: 94.05%\n",
            "Round 9\n",
            "Test Accuracy after Round 9: 94.71%\n",
            "Round 10\n",
            "Test Accuracy after Round 10: 94.93%\n",
            "Round 11\n",
            "Test Accuracy after Round 11: 94.88%\n",
            "Round 12\n",
            "Test Accuracy after Round 12: 95.07%\n",
            "Round 13\n",
            "Test Accuracy after Round 13: 94.63%\n",
            "Round 14\n",
            "Test Accuracy after Round 14: 95.41%\n",
            "Round 15\n",
            "Test Accuracy after Round 15: 95.04%\n",
            "Round 16\n",
            "Test Accuracy after Round 16: 95.53%\n",
            "Round 17\n",
            "Test Accuracy after Round 17: 95.70%\n",
            "Round 18\n",
            "Test Accuracy after Round 18: 95.67%\n",
            "Round 19\n",
            "Test Accuracy after Round 19: 95.46%\n",
            "Round 20\n",
            "Test Accuracy after Round 20: 95.81%\n"
          ]
        }
      ]
    }
  ]
}